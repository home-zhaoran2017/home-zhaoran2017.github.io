{"meta":{"title":"Ran's Homepage","subtitle":"Notes about technology and life.","description":"Love in the Future","author":"Ran Zhao","url":"http://yoursite.com"},"pages":[{"title":"分类","date":"2019-04-02T16:06:12.000Z","updated":"2020-01-08T16:35:58.385Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-11-17T11:47:09.000Z","updated":"2020-01-08T16:35:30.284Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"关于","date":"2019-04-02T16:03:44.000Z","updated":"2020-01-08T16:35:46.067Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"个人主页"}],"posts":[{"title":"时间数据类型处理","slug":"时间数据类型的处理","date":"2019-12-24T06:18:06.000Z","updated":"2020-01-08T18:00:07.781Z","comments":true,"path":"2019/12/24/时间数据类型的处理/","link":"","permalink":"http://yoursite.com/2019/12/24/时间数据类型的处理/","excerpt":"编写Python程序处理数据时，常遇到时间格式的字符串数据，有时涉及到时间的加减运算。在Python中，有专门的时间结构的数据对象来表示时间数据，实际中，我们常喜欢用字符串数据来表示时间，或者整型的时间戳。因此常涉及这三种时间数据类型的转换操作。","text":"编写Python程序处理数据时，常遇到时间格式的字符串数据，有时涉及到时间的加减运算。在Python中，有专门的时间结构的数据对象来表示时间数据，实际中，我们常喜欢用字符串数据来表示时间，或者整型的时间戳。因此常涉及这三种时间数据类型的转换操作。 获取当前时间戳 1seconds = time.time() 时间戳格式转时间格式 1time = time.localtime(seconds) 时间格式转字符串格式 1time.strftime(\"%Y-%m-%d %H:%M:%S\",time) 时间戳转换为字符串 1time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(seconds)) 字符串转换为时间戳 1time.mktime(time.strptime(\"2018-08-07\", \"%Y-%m-%d\")) [1] lwb444:《Python 时间戳/字符串/时间 转换》","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[]},{"title":"核主成分分析","slug":"核主成分分析","date":"2019-10-24T09:06:46.000Z","updated":"2020-01-08T18:01:25.767Z","comments":true,"path":"2019/10/24/核主成分分析/","link":"","permalink":"http://yoursite.com/2019/10/24/核主成分分析/","excerpt":"在核主成分分析中，我们认为原始数据集有更高的维数，我们可以在更高维的空间中做PCA分析（即在更高维空间里，把原始数据向不同的方向投影）。原因在于：在低维空间难以线性分类的数据点，我们有可能再更高维度上找到合适的高维线性分类平面。","text":"在核主成分分析中，我们认为原始数据集有更高的维数，我们可以在更高维的空间中做PCA分析（即在更高维空间里，把原始数据向不同的方向投影）。原因在于：在低维空间难以线性分类的数据点，我们有可能再更高维度上找到合适的高维线性分类平面。 一. 核函数 1. 核函数的定义 假设输入空间为X，特征空间为F（特征空间具有很高的维数，甚至无穷维），存在一个映射$\\phi$将空间X中的点x映射到空间F中的点f： $$ \\phi(x): X \\rightarrow F $$ 实际应用中，我们难以确定映射$\\phi$的具体形式，然而我们的主要计算需求是计算两个向量的内积，通过引入核函数，我们不需要知道映射的具体形式，便可通过低维空间的向量来计算高维空间向量的内积。 设：$x$，$z$是低维空间任意两个向量，那么核函数满足下述关系： $$ K(x,z) = \\phi(x) \\cdot \\phi(z) $$ 比如我们定义如下二维到三维的映射函数（这里，$x_i$表示样本$x$的第$i$个分量）： $$ \\phi(x) = (x_1^2, \\sqrt{2} x_1 x_2, x_2^2) $$ 可以验证： $$ K(x,z) = \\phi(x) \\cdot \\phi(z) = (x \\cdot z)^2 $$ 2. 核矩阵 任意两个样本点映射到高维空间后的内积组成的矩阵称为核函数矩阵（这里，$x_i$表示第$i$个样本）： $$ \\begin{bmatrix} \\phi(x_1) \\cdot \\phi(x_1) &amp; ... &amp; \\phi(x_1) \\cdot \\phi(x_N) \\\\ ... &amp; ... &amp; ... \\\\ \\phi(x_N) \\cdot \\phi(x_1) &amp; ... &amp; \\phi(x_N) \\cdot \\phi(x_N) \\end{bmatrix} $$ 常用的核函数的形式有如下几种： (1) 线性核 $$ K(x,z) = x \\cdot z $$ (2) 多项式核 $$ K(x,z) = (x \\cdot z + 1)^r, r \\in Z $$ (3) 高斯核 $$ K(x,z) = exp(-\\frac{|x-z|^2}{2\\sigma^2}), \\sigma \\in R, and\\ \\sigma \\neq 0$$ 采用核函数避免直接将原始向量映射到高维空间进行内积计算，一方面避开了映射函数的寻找，另一方面也减少了运算量。不过如果映射后的空间维数过高，导致模型在训练集上过拟合，在测试集上的泛化能力往往不加。 二. 核技巧 与线性主成分分析不同，核主成分分析通过在高维有映射后的特征空间进行主成分分析，设我们的原始数据矩阵为$X$： $$ [x_1, x_2, ..., x_N] $$ $x_i$表示数据集中的第$i$个样本，是一个维度为$d$的列向量，这里矩阵的每一列为一个样本，样本数为$N$。 我们通过映射函数$\\phi(x)$将所有样本映射到维度为$D$的特征空间$F$，映射后的数据矩阵为$\\phi(X)$： $$ [\\phi(x_1), \\phi(x_2), ..., \\phi(x_N)] $$ 接下来对数据集$\\phi(X)$进行PCA处理，这里预先假设$\\phi(X)$已经经过中心化处理： $$ \\sum_{i}^{N} \\phi(x_i) = 0 $$ 在特征空间里，数据集$\\phi(X)$的协方差矩阵为： $$ C_F = \\frac{1}{N} \\phi(X) \\phi(X)^T = \\frac{1}{N} \\sum_{i=1}^N \\phi(x_i) \\phi(x_i)^T $$ PCA计算实质是求解协方差矩阵$C_F$的本征值问题： $$ C_F p = \\lambda p $$ 即： $$ \\sum_{i=1}^N \\phi(x_i) \\phi(x_i)^T p = \\lambda p $$ 这里不考虑因子$\\frac{1}{N}$ 降维时我们考虑的是本征值$\\lambda \\neq 0$的成分，我们对上式两边同消去$\\lambda$，得到： $$ p = \\sum_{i=1}^N \\phi(x_i) [ \\phi(x_i)^T p ] $$ 注意到上式方括号中的值是一个常数，我们用$\\alpha_i$代替，于是： $$ p = \\sum_{i=1}^N \\alpha_i \\phi(x_i) = \\phi(X) \\alpha $$ $\\alpha$是一个$N$维的向量：$[\\alpha_1, \\alpha_2, ..., \\alpha_N]^T $ 这里得到一个结论：特征值不为0的特征向量可表示为高维空间样本向量的线性组合。 将上式带入$C_F$的本征方程中得： $$ \\phi(X)^T \\phi(X) \\phi(X)^T \\phi(X) \\alpha = \\lambda \\phi(X)^T \\phi(X) \\alpha $$ 定义核函数矩阵为：$K=\\phi(X)^T \\phi(X)$，上式化简为： $$ K \\cdot K \\alpha = \\lambda K \\alpha $$ 参考文献[1]证明为求解上式，则只需求解下述本征方程，该本征方程的特征值即原问题的本征值。 $$ K \\alpha = \\lambda \\alpha $$ [1] B. Scholkopf, A. J. Smola, K. Muller. Nonlinear component analysis as a kernel eigenvalue problem. Neural Computation 10 (5), 1299–1399, 1998.","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"主成分分析","slug":"主成分分析","date":"2019-10-24T08:14:19.000Z","updated":"2020-01-08T18:01:18.383Z","comments":true,"path":"2019/10/24/主成分分析/","link":"","permalink":"http://yoursite.com/2019/10/24/主成分分析/","excerpt":"主成分分析是数据降维的重要手段，当样本中包含多个特征且特征之间强耦合时，将强耦合的特征综合成一个或几个特征，这样既减少了样本的维度，节约计算资源也减少过拟合的风险。在主成分分析中，每一个主成分都是数据集在某一个方向上的投影，不同方向上数据集的方差(variance)由该方向上的特征值(eigenvalue)决定，一般我们选择最大的几个特征值所在的特征向量(eigenvector)，认为在这些方向上，数据集包含了我们所需要的信息。","text":"主成分分析是数据降维的重要手段，当样本中包含多个特征且特征之间强耦合时，将强耦合的特征综合成一个或几个特征，这样既减少了样本的维度，节约计算资源也减少过拟合的风险。在主成分分析中，每一个主成分都是数据集在某一个方向上的投影，不同方向上数据集的方差(variance)由该方向上的特征值(eigenvalue)决定，一般我们选择最大的几个特征值所在的特征向量(eigenvector)，认为在这些方向上，数据集包含了我们所需要的信息。 1. 数据集标准化 假设我们有一个数据集，每个样本有d个特征，共N个样本，我们构建一个$d \\times N$维的矩阵$X = [x_1, x_2, ..., x_N]$，矩阵的每一列对应一个样本，矩阵的每一行对应一个特征。 由于数据集中的每个特征来源于不同的变量，往往具有不同的量纲，数量级上相差较大，通常需将数据集进行标准化处理，即尽可能让特征分布接近标准正态分布（均值为0，标准差为1）。 $$ x' = \\frac{x-\\mu}{\\sigma} $$ $\\mu$，$\\sigma$分别是对应特征下的均值和标准差 2. 协方差矩阵 协方差矩阵是一个$d \\times d$的方阵，是计算两两特征之间的协方差得到的，故是一个对称方阵。 $$ C = E[(X-\\mu)(X-\\mu)^T] $$ $\\mu$是特征均值向量： $$\\mu = E(X) $$ 3. 协方差矩阵的特征值与特征向量 我们计算协方差矩阵的特征值和特征矢量，设d个特征矢量构成特征矩阵$U=[u_1, u_2, ..., u_d]$，d个特征值构成对角矩阵$\\Lambda = diag(\\lambda_1, \\lambda_2, ..., \\lambda_d)$，按照线性代数中矩阵特征矢量的定义有： $$ CU = U \\Lambda $$ 于是： $$ C = U \\Lambda U^T $$ 4. 方差贡献率 每个主成分有与其对应的本征值，决定这该主成分的方差，方差越大表示该主成分包含的信息越多，方差越小，表示包含的信息越少（通常是数据噪声，但有时这部分成分也包含重要信息）。我们按照方差从大到小排序，选择前k个主成分（通常设定阈值90%，前k个主成分的累积方差贡献率不低于90%）。 5. 数据降维 选择对应的k个特征向量构成变换矩阵$U_k=[u_1, u_2, ..., u_k]$，将变换矩阵作用在原始数据集上得到降维后的数据集： $$ Y = U_k^T X $$","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"特征工程","slug":"特征工程之分箱","date":"2019-08-14T08:54:07.000Z","updated":"2020-01-08T17:47:16.972Z","comments":true,"path":"2019/08/14/特征工程之分箱/","link":"","permalink":"http://yoursite.com/2019/08/14/特征工程之分箱/","excerpt":"","text":"","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/categories/Machine-Learning/"}],"tags":[]},{"title":"回归模型的评估指标","slug":"回归模型的评估指标","date":"2019-08-02T06:47:01.000Z","updated":"2019-08-02T07:14:55.833Z","comments":true,"path":"2019/08/02/回归模型的评估指标/","link":"","permalink":"http://yoursite.com/2019/08/02/回归模型的评估指标/","excerpt":"机器学习中回归模型的一些评估指标。","text":"机器学习中回归模型的一些评估指标。 1. 解释方差（Explained Variance） $$ EV(y, \\hat y) = 1 - \\frac{Var\\{y-\\hat y\\}}{Var\\{y\\}} $$ 2. 均方误差（MSE） $$ MSE(y, \\hat y) = \\frac{1}{n} \\sum_{i=1}^N (\\hat y_i - y_i)^2 $$ 3. 均方根误差（RMSE） $$ RMSE(y, \\hat y) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^N (\\hat y_i - y_i)^2} $$ 4. 平均绝对误差（MAE） $$ MAE(y, \\hat y) = \\frac{1}{N} \\sum_{i=1}^N |\\hat y_i - y_i| $$ 5. 均值平方对数误差（MSLE） $$ MSLE(y, \\hat y) = \\frac{1}{N} \\sum_{i=1}^N (ln(1+y_i)-ln(1+\\hat y_i))^2 $$ 6. 中位数绝对误差（MedianAE） $$ MedAE(y,\\hat y) = median(|y_1 - \\hat y_1|, ..., |y_n-\\hat y_n|) $$ 7. R方（R Squared） $$ R^2 = 1 - \\frac{\\sum_{i=1}^N(y_i - \\hat y_i)^2}{\\sum_{i=1}^N(y_i - \\bar y)^2 } $$ 结果在-1~1之间，如果结果为0，那么模型和猜测差不多，如果为1，说明模型没有误差，如果结果小于0，那么模型还不如随机猜测。","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"波士顿房价数据分析","slug":"波士顿房价数据分析","date":"2019-07-26T08:09:46.000Z","updated":"2020-01-08T17:55:40.194Z","comments":true,"path":"2019/07/26/波士顿房价数据分析/","link":"","permalink":"http://yoursite.com/2019/07/26/波士顿房价数据分析/","excerpt":"波士顿房价集来源于1978年美国某经济学杂志。该数据集包含若干波士顿房屋的价格及其各项数据，每个数据项包含14个数据，分别是房屋均价及周边犯罪率、是否在河边等相关信息，其中最后一个数据是房屋均价。","text":"波士顿房价集来源于1978年美国某经济学杂志。该数据集包含若干波士顿房屋的价格及其各项数据，每个数据项包含14个数据，分别是房屋均价及周边犯罪率、是否在河边等相关信息，其中最后一个数据是房屋均价。 数据集中有506条数据，13个特征，1个标签，这是一个回归问题。 各个特征字段的说明如下： 编号 字段 字段说明 1 CRIM 城镇人均犯罪率 2 ZN 住宅用地所占比例 3 INDUS 城镇中非商业用地所占比例 4 CHAS CHAS查尔斯和虚拟变量 5 NOX 环保指标(一氧化氮浓度) 6 RM 每栋住宅的房间数 7 AGE 1940年以前建成的自助单位比例 8 DIS 距离五个波士顿就业中心的加权距离 9 RAD 距离高速公路的便利指数 10 TAX 每一万美元的不动产税率 11 PTRATIO 城镇中教师学生比例 12 B 城镇中黑人比例 13 LSTAT 人口中地位低下者的比例 14 MEDV 平均房价 各特征的取值分布情况 (1) CRIM (2) ZN (3) INDUS (4) CHAS (5) NOX (6) (7) (8) (9) (10) (11) (12) (13) (14) 关联矩阵 关联矩阵","categories":[{"name":"Data Analysis","slug":"Data-Analysis","permalink":"http://yoursite.com/categories/Data-Analysis/"}],"tags":[]},{"title":"NexT主题配置教程","slug":"NexT主题配置教程","date":"2019-07-25T09:19:31.000Z","updated":"2019-07-25T09:19:31.094Z","comments":true,"path":"2019/07/25/NexT主题配置教程/","link":"","permalink":"http://yoursite.com/2019/07/25/NexT主题配置教程/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Hexo博客搭建教程","slug":"Hexo博客搭建教程","date":"2019-07-25T09:19:15.000Z","updated":"2019-07-25T09:19:15.624Z","comments":true,"path":"2019/07/25/Hexo博客搭建教程/","link":"","permalink":"http://yoursite.com/2019/07/25/Hexo博客搭建教程/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"json格式文件的导入与导出","slug":"json格式文件的导入与导出","date":"2019-05-15T06:38:23.000Z","updated":"2020-01-08T17:59:20.462Z","comments":true,"path":"2019/05/15/json格式文件的导入与导出/","link":"","permalink":"http://yoursite.com/2019/05/15/json格式文件的导入与导出/","excerpt":"JSON(JavaScript Object Notation)是一种轻量级的数据交换格式。它基于ECMAScript的一个子集。 JSON采用完全独立于语言的文本格式，但是也使用了类似于C语言家族的习惯(包括C、C++、Java、 JavaScript、Perl、Python 等)。这些特性使JSON成为理想的数据交换语言。易于人阅读和编写，同时也 易于机器解析和生成(一般用于提升网络传输速率)。","text":"JSON(JavaScript Object Notation)是一种轻量级的数据交换格式。它基于ECMAScript的一个子集。 JSON采用完全独立于语言的文本格式，但是也使用了类似于C语言家族的习惯(包括C、C++、Java、 JavaScript、Perl、Python 等)。这些特性使JSON成为理想的数据交换语言。易于人阅读和编写，同时也 易于机器解析和生成(一般用于提升网络传输速率)。 在Python中有默认的模块实现json数据的导入导出。 导入json模块 1import json 将Python字典转换为字符串 1234# 自定义一个python字典数据test_dict = &#123;'bigberg': [7600, &#123;1: [['iPhone', 6300], ['Bike', 800], ['shirt', 300]]&#125;]&#125;# 将字典转换为json字符串json_str = json.dumps(test_dict) 将字符串转换为Python字典 12# 将json字符串还原为字典new_dict = json.loads(json_str) 将Python字典写入json格式文件中 123# 将字典new_dict中的数据写入json格式文件中with open(\"record.json\",\"w\") as f: json.dump(new_dict,f) 从json格式文件中导入数据到Python字典 123with open(\"record.json\",'r') as load_f: load_dict = json.load(load_f) print(load_dict)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[]},{"title":"线性模型","slug":"线性模型","date":"2018-08-23T04:38:12.000Z","updated":"2020-01-08T17:46:11.241Z","comments":true,"path":"2018/08/23/线性模型/","link":"","permalink":"http://yoursite.com/2018/08/23/线性模型/","excerpt":"基本形式 由$d$个属性描述的实例$x=(x_1; x_2; ...; x_d)$，线性回归试图学得一个通过属性的线性组合来预测的函数： $$ f(x)=w_1 x_1 + w_2 x_2 + ... + w_d x_d + b $$","text":"基本形式 由$d$个属性描述的实例$x=(x_1; x_2; ...; x_d)$，线性回归试图学得一个通过属性的线性组合来预测的函数： $$ f(x)=w_1 x_1 + w_2 x_2 + ... + w_d x_d + b $$ 向量形式写成： $$ f(x)=w^T x+b $$ 其中 $w = (w_1; w_2; ...; w_d)$ 线性回归 设样本集的数目为$m$，$x$代表输入变量（特征），$y$代表输出变量（目标），$(x,y)$代表样本集中的实例，$(x^i,y^i)$代表样本集中第$i$个实例，函数$f(x)$是模型的假设。 1. 损失函数 模型的参数$w, b$决定模型预测能力的好坏，模型在训练集中的预测值与实际值的差距是我们的建模误差，代价函数即定义为建模误差的平方和： $ J(w, b) = \\frac{1}{2m} \\sum_{i=1}^{m}(f(x^i)-y^i)^2 $ 我们的目标是选择使代价函数最小的模型参数。 2. 梯度下降法 $w = w - \\alpha \\frac{\\partial}{\\partial w}J(w,b)$ $b = b - \\alpha \\frac{\\partial}{\\partial b}J(w,b)$ $\\alpha$ 是学习率 $\\frac{\\partial}{\\partial b}J(w,b) = \\frac{1}{m}\\sum_{i=1}^{m}(f(x^i)-y^i)$ $\\frac{\\partial}{\\partial w}J(w,b) = \\frac{1}{m}\\sum_{i=1}^{m}((f(x^i)-y^i) x^i)$ 3. 最小二乘法 逻辑回归 逻辑回归用来处理$y$值是离散情况的分类问题。 1. 分类问题 2. 假说表示 3. 判定边界 4. 代价函数与梯度下降 正则化","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"MNIST数据集","slug":"mnist数据集的导入","date":"2018-08-23T02:21:00.000Z","updated":"2020-01-08T18:00:52.492Z","comments":true,"path":"2018/08/23/mnist数据集的导入/","link":"","permalink":"http://yoursite.com/2018/08/23/mnist数据集的导入/","excerpt":"MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取，它包含了四个部分：","text":"MNIST 数据集可在 http://yann.lecun.com/exdb/mnist/ 获取，它包含了四个部分： Training set images： train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本) Training set labels： train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签) Test set images： t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本) Test set labels： t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签) MNIST 数据集来自美国国家标准与技术研究所，National Institute of Standards and Technology (NIST)，训练集 (training set) 由来自 250 个不同人手写的数字构成，其中 50% 是高中学生，50% 来自人口普查局 (the Census Bureau) 的工作人员。测试集(test set) 也是同样比例的手写数字数据。 图片是以字节的形式进行存储, 我们需要把它们读取到 NumPy array 中，以便训练和测试算法。 12345678910111213141516171819202122232425import osimport structimport numpy as npdef load_mnist(path, kind='train'): \"\"\"Load MNIST data from `path`\"\"\" labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind) images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind) with open(labels_path, 'rb') as lbpath: magic, n = struct.unpack('&gt;II', lbpath.read(8)) labels = np.fromfile(lbpath, dtype=np.uint8) with open(images_path, 'rb') as imgpath: magic, num, rows, cols = struct.unpack('&gt;IIII', imgpath.read(16)) images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784) return images, labels load_mnist 函数返回两个数组，第一个是一个 n x m 维的 NumPy array(images)，这里的 n 是样本数(行数)，m 是特征数(列数)。训练数据集包含 60000 个样本，测试数据集包含 10000 样本。在 MNIST 数据集中的每张图片由 28 x 28 个像素点构成，每个像素点用一个灰度值表示。在这里, 我们将 28 x 28 的像素展开为一个一维的行向量，这些行向量就是图片数组里的行(每行 784 个值，或者说每行就是代表了一张图片)。 load_mnist 函数返回的第二个数组(labels) 包含了相应的目标变量，也就是手写数字的类标签(整数 0-9)。 通过执行上面的代码，我们将会从刚刚解压 MNIST 数据集后的 mnist 目录下加载 60000 个训练样本和 10000 个测试样本。 为了了解 MNIST 中的图片看起来到底是个啥，让我们来对它们进行可视化处理。从 feature matrix 中将 784-像素值的向量 reshape 为之前的 28*28 的形状，然后通过 matplotlib 的 imshow 函数进行绘制： 1234567891011121314151617import matplotlib.pyplot as pltfig, ax = plt.subplots( nrows=2, ncols=5, sharex=True, sharey=True, )ax = ax.flatten()for i in range(10): img = X_train[y_train == i][0].reshape(28, 28) ax[i].imshow(img, cmap='Greys', interpolation='nearest')ax[0].set_xticks([])ax[0].set_yticks([])plt.tight_layout()plt.show() 此外，我们还可以绘制某一数字的多个样本图片，来看一下这些手写样本到底有多不同： 123456789101112131415fig, ax = plt.subplots( nrows=5, ncols=5, sharex=True, sharey=True, )ax = ax.flatten()for i in range(25): img = X_train[y_train == 7][i].reshape(28, 28) ax[i].imshow(img, cmap='Greys', interpolation='nearest')ax[0].set_xticks([])ax[0].set_yticks([])plt.tight_layout()plt.show()","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[]},{"title":"csv格式文件的导入与导出","slug":"csv格式文件的导入与导出","date":"2018-08-22T08:34:09.000Z","updated":"2020-01-08T17:58:55.471Z","comments":true,"path":"2018/08/22/csv格式文件的导入与导出/","link":"","permalink":"http://yoursite.com/2018/08/22/csv格式文件的导入与导出/","excerpt":"在数据处理中，常遇到csv格式的文件，下面简要介绍如何使用Python中的Pandas模块来读取csv文件中的数据。","text":"在数据处理中，常遇到csv格式的文件，下面简要介绍如何使用Python中的Pandas模块来读取csv文件中的数据。 CSV文件格式 CSV(Comma-Separated Values)文件以纯文本形式存储表格数据，文件由任意数目的记录 组成，记录间以换行符分隔，每条记录由字段组成，字段间的分隔符可自定义，通常是 逗号。下面的数据取自Kaggle中Titanic的乘客信息数据。 1234567891011PassengerId,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked892,3,&quot;Kelly, Mr. James&quot;,male,34.5,0,0,330911,7.8292,,Q893,3,&quot;Wilkes, Mrs. James (Ellen Needs)&quot;,female,47,1,0,363272,7,,S894,2,&quot;Myles, Mr. Thomas Francis&quot;,male,62,0,0,240276,9.6875,,Q895,3,&quot;Wirz, Mr. Albert&quot;,male,27,0,0,315154,8.6625,,S896,3,&quot;Hirvonen, Mrs. Alexander (Helga E Lindqvist)&quot;,female,22,1,1,3101298,12.2875,,S897,3,&quot;Svensson, Mr. Johan Cervin&quot;,male,14,0,0,7538,9.225,,S898,3,&quot;Connolly, Miss. Kate&quot;,female,30,0,0,330972,7.6292,,Q899,2,&quot;Caldwell, Mr. Albert Francis&quot;,male,26,1,1,248738,29,,S900,3,&quot;Abrahim, Mrs. Joseph (Sophie Halaut Easu)&quot;,female,18,0,0,2657,7.2292,,C901,3,&quot;Davies, Mr. John Samuel&quot;,male,21,2,0,A/4 48871,24.15,,S Pandas模块 导入pandas模块 1import pandas as pd 读取csv文件中的数据 1data = pd.read_csv(\"train.csv\",sep=',') 参数sep设定csv文件中分隔符，默认为,。 数据集对应的参数名 1data.columns 第 $i$ 条记录 1data.iloc[i-1] 数据集的大小 1data.shape 数据集的描述 1data.describe 数据集参数数组里的不同值 1titanic['Sex'].unique() 数据集字符串到数字的映射 12titanic.loc[titanic['Sex']=='male','Sex']=0titanic.loc[titanic['Sex']=='female','Sex']=1 数据集中缺失数据的补填 1titanic['Age']=titanic['Age'].fillna(titanic['Age'].median())","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[]}]}